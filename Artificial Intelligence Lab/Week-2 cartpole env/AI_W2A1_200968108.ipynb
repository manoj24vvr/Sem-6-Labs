{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Week-2** Creating a Simple Agent using Reinforcement Learning \n",
        "## **200968108 DSE-A 27**"
      ],
      "metadata": {
        "id": "a0qShsdjvCT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing the tensorflow agents package"
      ],
      "metadata": {
        "id": "fEa7TwEgywTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-agents[reverb]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdaHKK30y37M",
        "outputId": "3e7de92a-c755-47fd-d26b-841340bb6c77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (4.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (3.19.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.21.6)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.1.7)\n",
            "Requirement already satisfied: dm-reverb~=0.10.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.10.0)\n",
            "Requirement already satisfied: tensorflow==2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.51.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (15.0.6.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.30.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.1.21)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability>=0.18.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0->tf-agents[reverb]) (0.38.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.12.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using the CartPole-v0 Environment and writing a program to**"
      ],
      "metadata": {
        "id": "y_bKRG3Kvx1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "gjEH-9JNwPNR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fyWd5Pz_VwWa"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the **CartPole environment** from the openAI gym suite and taking a look at the **action** and **time_step_spec**."
      ],
      "metadata": {
        "id": "isylOuEJ5b6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the cartpole-v0 env.\n",
        "environment = suite_gym.load('CartPole-v0')\n",
        "\n",
        "print('action_spec:', environment.action_spec())\n",
        "\n",
        "print('\\ntime_step_spec.observation:', environment.time_step_spec().observation)\n",
        "print('\\ntime_step_spec.step_type:', environment.time_step_spec().step_type)\n",
        "print('\\ntime_step_spec.discount:', environment.time_step_spec().discount)\n",
        "print('\\ntime_step_spec.reward:', environment.time_step_spec().reward)\n"
      ],
      "metadata": {
        "id": "qjoKcyln2xHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c4e947-e1fc-4cf0-ac84-22cf44b154ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_spec: BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n",
            "\n",
            "time_step_spec.observation: BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n",
            "\n",
            "time_step_spec.step_type: ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')\n",
            "\n",
            "time_step_spec.discount: BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)\n",
            "\n",
            "time_step_spec.reward: ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrapping the **Python** environment into a **TensorFlow** environment using the `TFPyEnvironment` wrapper."
      ],
      "metadata": {
        "id": "azMddyxu8UGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_env = tf_py_environment.TFPyEnvironment(environment)\n",
        "\n",
        "print(isinstance(tf_env, tf_environment.TFEnvironment))\n",
        "print(\"\\nTimeStep Specs:\", tf_env.time_step_spec())\n",
        "print(\"\\nAction Specs:\", tf_env.action_spec())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOE2Vral5tys",
        "outputId": "5000df3d-7b78-4f81-c283-0d6577a36ff7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "\n",
            "TimeStep Specs: TimeStep(\n",
            "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
            " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
            "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
            "      dtype=float32)),\n",
            " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
            " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
            "\n",
            "Action Specs: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the specs are now of type: `(Bounded)TensorSpec`."
      ],
      "metadata": {
        "id": "rneJTx-h8eeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Running the CartPole-v0 environment.**\n",
        "**a.Implement the CartPole environment for a certain number of steps**\n",
        "* Every cycle of state-action-reward is called a step. \n"
      ],
      "metadata": {
        "id": "eM-oHTGK8myh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset() creates the initial time_step after resetting the environment.\n",
        "time_step = tf_env.reset()\n",
        "\n",
        "num_steps = 10\n",
        "\n",
        "transitions = []\n",
        "reward = 0\n",
        "for i in range(num_steps):\n",
        "  action = tf.constant([i % 2])\n",
        "  # applies the action and returns the new TimeStep.\n",
        "  next_time_step = tf_env.step(action)\n",
        "  transitions.append([time_step, action, next_time_step])\n",
        "  reward += next_time_step.reward\n",
        "  time_step = next_time_step\n",
        "\n",
        "np_transitions = tf.nest.map_structure(lambda x: x.numpy(), transitions)\n",
        "print('\\n\\n\\n'.join(map(str, np_transitions)))\n",
        "print('\\n\\nTotal rewards:', int(reward))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uZrhaBhjdRs",
        "outputId": "9477c098-18e3-41ae-f53e-ae801ef2460d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03550508,  0.01080811,  0.03991103, -0.04246571]],\n",
            "      dtype=float32),\n",
            " 'reward': array([0.], dtype=float32),\n",
            " 'step_type': array([0], dtype=int32)}), array([0], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03572123, -0.18486275,  0.03906171,  0.2625376 ]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03572123, -0.18486275,  0.03906171,  0.2625376 ]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([1], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03202398,  0.00968049,  0.04431247, -0.01757345]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03202398,  0.00968049,  0.04431247, -0.01757345]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([0], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03221759, -0.18604802,  0.043961  ,  0.2887547 ]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.03221759, -0.18604802,  0.043961  ,  0.2887547 ]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([1], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.02849663, 0.00842037, 0.04973609, 0.01025432]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.02849663, 0.00842037, 0.04973609, 0.01025432]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([0], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.02866504, -0.18737827,  0.04994118,  0.3182055 ]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.02866504, -0.18737827,  0.04994118,  0.3182055 ]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([1], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.02491747, 0.00699812, 0.05630529, 0.04168102]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.02491747, 0.00699812, 0.05630529, 0.04168102]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([0], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.02505743, -0.18888414,  0.05713891,  0.35158378]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.02505743, -0.18888414,  0.05713891,  0.35158378]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([1], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.02127975, 0.00538067, 0.06417058, 0.07745183]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.02127975, 0.00538067, 0.06417058, 0.07745183]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([0], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.02138736, -0.19059971,  0.06571962,  0.38967055]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "[TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[ 0.02138736, -0.19059971,  0.06571962,  0.38967055]],\n",
            "      dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)}), array([1], dtype=int32), TimeStep(\n",
            "{'discount': array([1.], dtype=float32),\n",
            " 'observation': array([[0.01757537, 0.0035309 , 0.07351303, 0.11841092]], dtype=float32),\n",
            " 'reward': array([1.], dtype=float32),\n",
            " 'step_type': array([1], dtype=int32)})]\n",
            "\n",
            "\n",
            "Total rewards: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b.Implement the CartPole environment for a certain number of episodes**\n",
        "* The reinforcement learning system continues to iterate through cycles until it reaches the desired state or a maximum number of steps are expired. This series of steps is called an episode.\n",
        "\n",
        "* An episode is larger than a step and usually contains many steps"
      ],
      "metadata": {
        "id": "P0Vxh6IXfEMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the number of episodes\n",
        "\n",
        "num_episodes = 10\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "avg_rewards_list = []\n",
        "steps = []\n",
        "\n",
        "for i in range(num_episodes):\n",
        "\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "\n",
        "  while not time_step.is_last():\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "\n",
        "  num_steps = np.sum(steps)\n",
        "  avg_length = np.mean(steps)\n",
        "  avg_rewards_list.append(avg_length)\n",
        "\n",
        "  print('Episode:', (i+1),'\\tSteps: ', episode_steps)\n",
        "\n",
        "print(\"\\n\\nEpisodes: \",num_episodes)\n",
        "print('\\nTotalsteps:', num_steps)\n",
        "print('\\navg_length: ', avg_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrF8no5-58zy",
        "outputId": "0e8de299-b844-4827-dcc9-dd9ac87138b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1 \tSteps:  12\n",
            "Episode: 2 \tSteps:  17\n",
            "Episode: 3 \tSteps:  21\n",
            "Episode: 4 \tSteps:  34\n",
            "Episode: 5 \tSteps:  15\n",
            "Episode: 6 \tSteps:  23\n",
            "Episode: 7 \tSteps:  48\n",
            "Episode: 8 \tSteps:  22\n",
            "Episode: 9 \tSteps:  17\n",
            "Episode: 10 \tSteps:  29\n",
            "\n",
            "\n",
            "Episodes:  10\n",
            "\n",
            "Totalsteps: 238\n",
            "\n",
            "avg_length:  23.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Avg. Total Rewards over \",num_episodes,' episodes is ',avg_rewards_list[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOEYayBII1qs",
        "outputId": "db76de9d-773e-4b1f-da87-537a18003d41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg. Total Rewards over  10  episodes is  23.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Vizualising the avg. rewards acquired after each episode**"
      ],
      "metadata": {
        "id": "kiI1NqQFfKcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iterations = range(1, num_episodes+1)\n",
        "plt.plot(iterations, avg_rewards_list)\n",
        "plt.title(\"\\nAvg. Return over Episodes\\n\")\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Episodes')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "atztKa_FEYAT",
        "outputId": "c3ff3dc8-e508-4865-e3ad-b18093f59a27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Episodes')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c.Compare and comment on the rewards earned for both approaches.**\n"
      ],
      "metadata": {
        "id": "D9rzu9soGnCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the first approach, we can observe that total rewards[10] is always the \n",
        "same as no. of steps[10] defined, but in the second approach total rewards[24] are greater than no. of given episodes[10].\n",
        "* Hence, we can say implementing the cartpole environment on certain number of episodes would give us a better result as the number of rewards are always greater.\n",
        "* As the agent trains a policy to choose actions to maximize the sum of rewards, also known as return, the approach which includes running certain number of episodes is a better and an efficient one."
      ],
      "metadata": {
        "id": "PSsB3kYYr2Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmaUc2lIIJrs"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}